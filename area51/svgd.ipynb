{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:59:02.572935Z",
     "start_time": "2024-07-06T15:59:02.057686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "\n",
    "class SVGDLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, rank, num_particles):\n",
    "        super(SVGDLayer, self).__init__()\n",
    "        self.rank = rank\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_particles = num_particles\n",
    "\n",
    "        # Initialize particles\n",
    "        self.particles_u = nn.ParameterList([nn.Parameter(torch.randn(input_dim, rank)) for _ in range(num_particles)])\n",
    "        self.particles_v = nn.ParameterList([nn.Parameter(torch.randn(rank, output_dim)) for _ in range(num_particles)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for u, v in zip(self.particles_u, self.particles_v):\n",
    "            low_rank_approx = torch.matmul(u, v)\n",
    "            outputs.append(torch.matmul(x, low_rank_approx))\n",
    "        return torch.stack(outputs).mean(dim=0)\n",
    "\n",
    "    def svgd_update(self, loss_fn, x, y, lr=0.001, bandwidth=1.0):\n",
    "        grads_u = []\n",
    "        grads_v = []\n",
    "        particles = list(zip(self.particles_u, self.particles_v))\n",
    "\n",
    "        # Compute gradients for each particle\n",
    "        for u, v in particles:\n",
    "            u.requires_grad_(True)\n",
    "            v.requires_grad_(True)\n",
    "            low_rank_approx = torch.matmul(u, v)\n",
    "            output = torch.matmul(x, low_rank_approx)\n",
    "            loss = loss_fn(output, y)\n",
    "            grad_u, grad_v = grad(loss, [u, v], create_graph=True)\n",
    "            grads_u.append(grad_u)\n",
    "            grads_v.append(grad_v)\n",
    "\n",
    "        # Update each particle\n",
    "        for i, (u, v) in enumerate(particles):\n",
    "            k_u = torch.zeros_like(u)\n",
    "            k_v = torch.zeros_like(v)\n",
    "            phi_u = torch.zeros_like(u)\n",
    "            phi_v = torch.zeros_like(v)\n",
    "            for j, (u_j, v_j) in enumerate(particles):\n",
    "                k_ij = self.kernel(u, u_j, bandwidth)\n",
    "                k_u += k_ij * grads_u[j]\n",
    "                k_v += k_ij * grads_v[j]\n",
    "                phi_u += k_ij * (u_j - u)\n",
    "                phi_v += k_ij * (v_j - v)\n",
    "            self.particles_u[i].data += lr * (k_u / self.num_particles - phi_u / self.num_particles)\n",
    "            self.particles_v[i].data += lr * (k_v / self.num_particles - phi_v / self.num_particles)\n",
    "\n",
    "    def kernel(self, x1, x2, h=1.0):\n",
    "        sq_dist = torch.sum((x1 - x2)**2)\n",
    "        return torch.exp(-sq_dist / (2 * h**2))\n",
    "\n",
    "class SVGDRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, rank, num_particles):\n",
    "        super(SVGDRegressionModel, self).__init__()\n",
    "        self.svgd_layer = SVGDLayer(input_dim, output_dim, rank, num_particles)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.svgd_layer(x)\n",
    "\n",
    "# Create a toy dataset\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(100, 10)\n",
    "true_weights = torch.randn(10, 1)\n",
    "y = x @ true_weights + 0.1 * torch.randn(100, 1)\n",
    "\n",
    "# Normalize the dataset\n",
    "x = (x - x.mean(dim=0)) / x.std(dim=0)\n",
    "y = (y - y.mean(dim=0)) / y.std(dim=0)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "input_dim = 10\n",
    "output_dim = 1\n",
    "rank = 5\n",
    "num_particles = 10\n",
    "model = SVGDRegressionModel(input_dim, output_dim, rank, num_particles)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = loss_fn(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.svgd_layer.svgd_update(loss_fn, x, y)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ],
   "id": "f395727743179a3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 10.68558120727539\n",
      "Epoch 10, Loss: 10.796398162841797\n",
      "Epoch 20, Loss: 10.94674301147461\n",
      "Epoch 30, Loss: 11.143123626708984\n",
      "Epoch 40, Loss: 11.393436431884766\n",
      "Epoch 50, Loss: 11.70773696899414\n",
      "Epoch 60, Loss: 12.099539756774902\n",
      "Epoch 70, Loss: 12.587889671325684\n",
      "Epoch 80, Loss: 13.199819564819336\n",
      "Epoch 90, Loss: 13.974235534667969\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T16:01:14.125548Z",
     "start_time": "2024-07-06T16:01:14.040240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "class SVGDLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, rank, num_particles, lora_alpha, lora_dropout, merge_weights):\n",
    "        super(SVGDLayer, self).__init__()\n",
    "        self.rank = rank\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_particles = num_particles\n",
    "        self.lora_alpha = lora_alpha\n",
    "        self.lora_dropout = nn.Dropout(p=lora_dropout) if lora_dropout > 0. else lambda x: x\n",
    "        self.merge_weights = merge_weights\n",
    "        self.merged = False\n",
    "\n",
    "        # Initialize particles\n",
    "        self.particles_u = nn.ParameterList([nn.Parameter(torch.randn(input_dim, rank)) for _ in range(num_particles)])\n",
    "        self.particles_v = nn.ParameterList([nn.Parameter(torch.randn(rank, output_dim)) for _ in range(num_particles)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for u, v in zip(self.particles_u, self.particles_v):\n",
    "            low_rank_approx = torch.matmul(u, v)\n",
    "            outputs.append(torch.matmul(x, low_rank_approx))\n",
    "        return torch.stack(outputs).mean(dim=0)\n",
    "\n",
    "    def calculate_adaptive_scaling(self, grad_u, grad_v):\n",
    "        norm_u = torch.norm(grad_u, p='fro')\n",
    "        norm_v = torch.norm(grad_v, p='fro')\n",
    "        adaptive_scaling = (self.lora_alpha / self.rank) * (norm_u + norm_v) / (norm_u + norm_v + 1e-8)\n",
    "        return adaptive_scaling\n",
    "\n",
    "    def adjust_rank(self, grad_u, grad_v):\n",
    "        pass  \n",
    "    \n",
    "    def svgd_update(self, grads_u, grads_v, lr=0.01):\n",
    "        for i, (u, v) in enumerate(zip(self.particles_u, self.particles_v)):\n",
    "            self.particles_u[i].data += lr * grads_u[i]\n",
    "            self.particles_v[i].data += lr * grads_v[i]\n",
    "\n",
    "    def compute_gradients(self, loss_fn, x, y):\n",
    "        grads_u = []\n",
    "        grads_v = []\n",
    "        for u, v in zip(self.particles_u, self.particles_v):\n",
    "            low_rank_approx = torch.matmul(u, v)\n",
    "            output = torch.matmul(x, low_rank_approx)\n",
    "            loss = loss_fn(output, y)\n",
    "            grad_u, grad_v = grad(loss, [u, v])\n",
    "            grads_u.append(grad_u)\n",
    "            grads_v.append(grad_v)\n",
    "        return grads_u, grads_v\n",
    "\n",
    "class SVGDEmbedding(nn.Embedding):\n",
    "    def __init__(self, num_embeddings, embedding_dim, rank, num_particles, lora_alpha, lora_dropout, merge_weights, **kwargs):\n",
    "        super(SVGDEmbedding, self).__init__(num_embeddings, embedding_dim, **kwargs)\n",
    "        self.svgd_layer = SVGDLayer(embedding_dim, embedding_dim, rank, num_particles, lora_alpha, lora_dropout, merge_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding_output = super(SVGDEmbedding, self).forward(x)\n",
    "        return self.svgd_layer(embedding_output)\n",
    "\n",
    "class SVGDLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, rank, num_particles, lora_alpha, lora_dropout, merge_weights, **kwargs):\n",
    "        super(SVGDLinear, self).__init__(in_features, out_features, **kwargs)\n",
    "        self.svgd_layer = SVGDLayer(in_features, out_features, rank, num_particles, lora_alpha, lora_dropout, merge_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear_output = super(SVGDLinear, self).forward(x)\n",
    "        return self.svgd_layer(linear_output)\n",
    "\n",
    "embedding = SVGDEmbedding(10000, 512, rank=10, num_particles=10, lora_alpha=1, lora_dropout=0.1, merge_weights=True)\n",
    "linear = SVGDLinear(512, 512, rank=10, num_particles=10, lora_alpha=1, lora_dropout=0.1, merge_weights=True)"
   ],
   "id": "60a7e42c20024293",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b3fd3999211717ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
